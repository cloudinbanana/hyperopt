{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oyperopt自动化调参"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了方便大家复现, 我们使用kaggle比赛中的公共数据 \"caravan-insurance-challenge.csv\"( https://www.kaggle.com/uciml/caravan-insurance-challenge).\n",
    "该比赛旨在预测并解释客户购买房车旅行保险的可能性, 是一个典型的二元分类有监督学习.\n",
    "每条记录并不是以\"人\"为单位而是以邮递地址为单位的\"家庭\"数据.\n",
    "解释性特征有85个, 包括人口统计以及保险产品统计等方面的数据, 详情请参考以上链接."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd # 数据处理\n",
    "\n",
    "import numpy as np # 数据处理\n",
    "import random #生成随机数\n",
    "import lightgbm as lgb #lgbm模型\n",
    "from sklearn.model_selection import KFold #n折交叉检验\n",
    "import csv #用于结果输出与csv\n",
    "from hyperopt import STATUS_OK # \"status\"\n",
    "\n",
    "# 画图\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(123) #复现随机数\n",
    "MAX_EVALS = 200 #调参过程迭代次数\n",
    "N_FOLDS = 10 #10折交叉检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (5822, 85)\n",
      "Test shape:  (4000, 85)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOSTYPE</th>\n",
       "      <th>MAANTHUI</th>\n",
       "      <th>MGEMOMV</th>\n",
       "      <th>MGEMLEEF</th>\n",
       "      <th>MOSHOOFD</th>\n",
       "      <th>MGODRK</th>\n",
       "      <th>MGODPR</th>\n",
       "      <th>MGODOV</th>\n",
       "      <th>MGODGE</th>\n",
       "      <th>MRELGE</th>\n",
       "      <th>...</th>\n",
       "      <th>ALEVEN</th>\n",
       "      <th>APERSONG</th>\n",
       "      <th>AGEZONG</th>\n",
       "      <th>AWAOREG</th>\n",
       "      <th>ABRAND</th>\n",
       "      <th>AZEILPL</th>\n",
       "      <th>APLEZIER</th>\n",
       "      <th>AFIETS</th>\n",
       "      <th>AINBOED</th>\n",
       "      <th>ABYSTAND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MOSTYPE  MAANTHUI  MGEMOMV  MGEMLEEF  MOSHOOFD  MGODRK  MGODPR  MGODOV  \\\n",
       "0       33         1        3         2         8       0       5       1   \n",
       "1       37         1        2         2         8       1       4       1   \n",
       "2       37         1        2         2         8       0       4       2   \n",
       "3        9         1        3         3         3       2       3       2   \n",
       "4       40         1        4         2        10       1       4       1   \n",
       "\n",
       "   MGODGE  MRELGE    ...     ALEVEN  APERSONG  AGEZONG  AWAOREG  ABRAND  \\\n",
       "0       3       7    ...          0         0        0        0       1   \n",
       "1       4       6    ...          0         0        0        0       1   \n",
       "2       4       3    ...          0         0        0        0       1   \n",
       "3       4       5    ...          0         0        0        0       1   \n",
       "4       4       7    ...          0         0        0        0       1   \n",
       "\n",
       "   AZEILPL  APLEZIER  AFIETS  AINBOED  ABYSTAND  \n",
       "0        0         0       0        0         0  \n",
       "1        0         0       0        0         0  \n",
       "2        0         0       0        0         0  \n",
       "3        0         0       0        0         0  \n",
       "4        0         0       0        0         0  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读入数据\n",
    "root_path = 'C:/Users/baiyunfei3/Desktop/notebook/hyperopt'\n",
    "data_path = root_path+'/caravan-insurance-challenge/caravan-insurance-challenge.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "train = data[data['ORIGIN'] == 'train']\n",
    "test = data[data['ORIGIN'] == 'test']\n",
    "\n",
    "# 提取标签\n",
    "train_labels = np.array(train['CARAVAN'].astype(np.int32)).reshape((-1,))\n",
    "test_labels = np.array(test['CARAVAN'].astype(np.int32)).reshape((-1,))\n",
    "\n",
    "# 删除多余字段\n",
    "train = train.drop(columns = ['ORIGIN', 'CARAVAN'])\n",
    "test = test.drop(columns = ['ORIGIN', 'CARAVAN'])\n",
    "\n",
    "features = np.array(train)\n",
    "test_features = np.array(test)\n",
    "labels = train_labels[:]\n",
    "\n",
    "print('Train shape: ', train.shape)\n",
    "print('Test shape: ', test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ORIGIN\n",
       "test     5.950000\n",
       "train    5.977327\n",
       "Name: CARAVAN, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['ORIGIN'])['CARAVAN'].mean()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查标签占比情况, 我们发现购买保险的记录在训练集和测试集中仅约6%, 极度不平衡.\n",
    "由于本文关注于调参, 将不纠结于处理不平衡数据的方法和特征工程, 只是选用AUC而非error rate作为衡量模型优劣的指标."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基准模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
      "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
      "\n",
      "The baseline score on the test set is 0.7092.\n",
      "The baseline training time is 0.5384 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Model with default hyperparameters\n",
    "model = lgb.LGBMClassifier()\n",
    "\n",
    "\n",
    "start = timer()\n",
    "model.fit(features, labels)\n",
    "train_time = timer() - start\n",
    "\n",
    "predictions = model.predict_proba(test_features)[:, 1]\n",
    "auc = roc_auc_score(test_labels, predictions)\n",
    "\n",
    "print(model)\n",
    "print('\\nThe baseline score on the test set is {:.4f}.'.format(auc))\n",
    "print('The baseline training time is {:.4f} seconds'.format(train_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用LGBM的默认超参数得到了测试集底线AUC≈0.7092"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperopt调参"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调参时, 我们需要准备好以下4个部分:\n",
    "\n",
    "目标函数, 也就是我们的f(x), 这里是训练集的10折交叉检验的平均AUC. 由于Hyperopt进行的是最小值优化, 故考虑使用 1- AUC;\n",
    "\n",
    "定义超参数空间;\n",
    "\n",
    "优化算法: 先验假设(TPE)和采集函数(MEI);\n",
    "\n",
    "调参过程记录."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目标函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  lgb 数据集\n",
    "train_set = lgb.Dataset(features, label = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 以下定义目标函数\n",
    "def objective(params, n_folds = N_FOLDS):\n",
    "    \"\"\"Hyperopt 中 LGBM 的目标函数\"\"\"\n",
    "    \n",
    "    # 记录迭代次数\n",
    "    global ITERATION    \n",
    "    ITERATION += 1\n",
    "    \n",
    "    # 'boosting_type' 与 'subsample' 以来参数, 需要\"unpack\". 继续看'2.2.2'部分就明白了\n",
    "    subsample = params['boosting_type'].get('subsample', 1.0)    \n",
    "    params['boosting_type'] = params['boosting_type']['boosting_type']\n",
    "    params['subsample'] = subsample\n",
    "    \n",
    "    # 确保超参数数值类型的正确性, 否侧Hyperopt会报错\n",
    "    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "        params[parameter_name] = int(params[parameter_name])\n",
    "    \n",
    "    start = timer()     \n",
    "    # 进行10折交叉检验, 由于设置了early_stopping, num_boost_round设置相对高一些也不必担心\n",
    "    cv_results = lgb.cv(params, train_set, num_boost_round = 10000, nfold = n_folds, \n",
    "                        early_stopping_rounds = 100, metrics = 'auc', seed = 50)    \n",
    "    run_time = timer() - start\n",
    "    \n",
    "    # 找出cv中最大平均AUC\n",
    "    best_score = np.max(cv_results['auc-mean'])\n",
    "    loss = 1 - best_score\n",
    "    \n",
    "    # 最大平均AUC 对应的提升树的迭代次数\n",
    "    n_estimators = int(np.argmax(cv_results['auc-mean']) + 1)\n",
    "\n",
    "    # 将我们关心的结果输出至 csv 文件, 注意要用 'a', append\n",
    "    of_connection = open(out_file, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([loss, params, ITERATION, n_estimators, run_time])\n",
    "    \n",
    "    # 同时也可将结果存在返回结果中\n",
    "    return {'loss': loss, 'params': params, 'iteration': ITERATION,\n",
    "            'estimators': n_estimators, \n",
    "            'train_time': run_time, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义超参数空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "\n",
    "# 定义超参数空间\n",
    "space = {\n",
    "    'class_weight': hp.choice('class_weight', [None, 'balanced']),\n",
    "    'boosting_type': hp.choice('boosting_type', [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n",
    "                                                 {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n",
    "                                                 {'boosting_type': 'goss', 'subsample': 1.0}]),\n",
    "    'num_leaves': hp.quniform('num_leaves', 30, 150, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperopt 提供了10种定义参数空间的分布(详情可参考https://github.com/hyperopt/hyperopt/wiki/FMin):\n",
    "\n",
    "hp.choice(label, options): 离散的均匀分布, 适用于参数中类别的选择, 如\"boosting_type\"中选择\"gbdt\", \"dart\", \"goss\";\n",
    "\n",
    "hp.randint(label, upper): [0, upper) 定义域的整数均分布;\n",
    "\n",
    "hp.uniform(label, low, high): [low, high] 定义域的均匀分布;\n",
    "\n",
    "hp.quniform(label, low, high, q): round(uniform(low, high) / q) * q;\n",
    "\n",
    "hp.loguniform(label, low, high): exp(uniform(low, high)), 适用于夸量级的参数, 如learning_rate;\n",
    "\n",
    "hp.qloguniform(label, low, high, q): round(exp(uniform(low, high)) / q) * q;\n",
    "\n",
    "hp.normal(label, mu, sigma): 正态分布;\n",
    "\n",
    "hp.qnormal(label, mu, sigma, q): round(normal(mu, sigma) / q) * q;\n",
    "\n",
    "hp.lognormal(label, mu, sigma): exp(normal(mu, sigma));\n",
    "\n",
    "hp.qlognormal(label, mu, sigma, q): round(exp(normal(mu, sigma)) / q) * q;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import tpe\n",
    "\n",
    "# TPE + MEI 算法\n",
    "tpe_algorithm = tpe.suggest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 记录过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import Trials\n",
    "\n",
    "# csv 存储\n",
    "out_path = root_path+'/results/gbm_trials.csv'\n",
    "out_file = out_path\n",
    "of_connection = open(out_file, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "writer.writerow(['loss', 'params', 'iteration', 'estimators', 'train_time']) # 制作表头\n",
    "of_connection.close()\n",
    "\n",
    "# 利用 Trials 实例存储\n",
    "bayes_trials = Trials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from hyperopt import fmin\n",
    "\n",
    "# 目标函数中的全局变量, 纪录迭代次数\n",
    "global  ITERATION\n",
    "ITERATION = 0\n",
    "\n",
    "# 正式开始优化\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
    "            max_evals = MAX_EVALS, trials = bayes_trials, rstate = np.random.RandomState(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_results = pd.DataFrame(bayes_trials.results, columns=['loss', 'params', 'iteration', 'estimators', 'train_time'])\n",
    "bayes_results.sort_values('loss', ascending = True, inplace = True)\n",
    "bayes_results.reset_index(inplace = True, drop = True)\n",
    "bayes_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_results.loc[0,'params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10折交叉检验中, 使用以上超参数最优平均loss达到了约0.229. 现在我们来看一下这组最优参数在测试集的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取最优参数\n",
    "best_bayes_estimators = int(bayes_results.loc[0, 'estimators'])\n",
    "best_bayes_params = bayes_results.loc[0, 'params'].copy()\n",
    "\n",
    "# 使用全量训练集建模\n",
    "best_bayes_model = lgb.LGBMClassifier(n_estimators=best_bayes_estimators, n_jobs = -1, \n",
    "                                       objective = 'binary', random_state = 50, **best_bayes_params)\n",
    "best_bayes_model.fit(features, labels)\n",
    "\n",
    "# 测试机表现\n",
    "preds = best_bayes_model.predict_proba(test_features)[:, 1]\n",
    "print('Bayes优化测试集AUC: {:.5f}.'.format(roc_auc_score(test_labels, preds)))\n",
    "print('使用 {} 树达到该效果'.format(bayes_results.loc[0, 'estimators']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_results['train_time'].sum()/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "200次贝叶斯优化迭代共耗时约10分钟，找到的参数组合仅使用25棵树达到AUC≈0.7255的结果，对比基线模型100棵树的0.7092确实有所提高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机搜索调参\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. 目标函数\n",
    "def random_objective(params, iteration, n_folds = N_FOLDS):\n",
    "    \"\"\"\n",
    "    随机搜索\n",
    "    入参: 超参数组合;\n",
    "    出参: loss, params, iteration, n_estimators, train_time.\n",
    "    \"\"\"\n",
    "    start = timer()\n",
    "    \n",
    "    # 10折交叉检验\n",
    "    cv_results = lgb.cv(params, train_set, num_boost_round = 10000, nfold = n_folds, \n",
    "                        early_stopping_rounds = 100, metrics = 'auc', seed = 50)\n",
    "    end = timer()\n",
    "    \n",
    "    # 收集结果\n",
    "    best_score = np.max(cv_results['auc-mean'])\n",
    "    loss = 1 - best_score\n",
    "    n_estimators = int(np.argmax(cv_results['auc-mean']) + 1)\n",
    "    return [loss, params, iteration, n_estimators, end - start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. 超参数空间\n",
    "param_grid = {\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'boosting_type': ['gbdt', 'goss', 'dart'],\n",
    "    'num_leaves': list(range(30, 150)),\n",
    "    'learning_rate': list(np.logspace(np.log(0.005), np.log(0.2), base = np.exp(1), num = 1000)),\n",
    "    'subsample_for_bin': list(range(20000, 300000, 20000)),\n",
    "    'min_child_samples': list(range(20, 500, 5)),\n",
    "    'reg_alpha': list(np.linspace(0, 1)),\n",
    "    'reg_lambda': list(np.linspace(0, 1)),\n",
    "    'colsample_bytree': list(np.linspace(0.6, 1, 10))\n",
    "}\n",
    "subsample_dist = list(np.linspace(0.5, 1, 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "random.seed(50)\n",
    "random_results = pd.DataFrame(columns = ['loss', 'params', 'iteration', 'estimators', 'train_time'],\n",
    "                       index = list(range(MAX_EVALS)))\n",
    "\n",
    "# 迭代200次\n",
    "for i in range(MAX_EVALS):\n",
    "    \n",
    "    # 随机搜索\n",
    "    params = {key: random.sample(value, 1)[0] for key, value in param_grid.items()}\n",
    "    params['subsample'] =random.sample(subsample_dist, 1)[0] if params['boosting_type'] != 'goss' else 1.0\n",
    "    results_list = random_objective(params, i)\n",
    "    \n",
    "    # 记录过程\n",
    "    random_results.loc[i, :] = results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化结果\n",
    "random_results.sort_values('loss', ascending = True, inplace = True)\n",
    "random_results.reset_index(inplace = True, drop = True)\n",
    "random_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_results.loc[0, 'params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_params = random_results.loc[0, 'params'].copy()\n",
    "best_random_estimators = int(random_results.loc[0, 'estimators'])\n",
    "best_random_model = lgb.LGBMClassifier(n_estimators=best_random_estimators, n_jobs = -1, \n",
    "                                       objective = 'binary', **best_random_params, random_state = 50)\n",
    "\n",
    "# Fit on the training data\n",
    "best_random_model.fit(features, labels)\n",
    "\n",
    "# Make test predictions\n",
    "predictions = best_random_model.predict_proba(test_features)[:, 1]\n",
    "\n",
    "\n",
    "print('随机搜索最优参数得到AUC:  {:.4f}.'.format(roc_auc_score(test_labels, predictions)))\n",
    "print('使用 {} 树达到该效果.'.format(random_results.loc[0, 'estimators']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机搜索最优参数得到AUC:  0.7262.\n",
    "使用 197 树达到该效果."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_results['train_time'].sum()/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "200次随机搜索迭代共耗时约14分钟, 使用197棵树达到AUC≈0.7262, 虽然比Bayes优化效果略好, 但其模型复杂度(197)远高于Bayes(25)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结果对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = pd.DataFrame(best_bayes_params, index = ['Bayesian optimization']).append(pd.DataFrame(best_random_params, index = ['random search']), \n",
    "                                                                  ignore_index = False)\n",
    "\n",
    "best_params.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机搜索\n",
    "random_params = pd.DataFrame(list(random_results['params']))\n",
    "random_params['loss'] = random_results['loss']\n",
    "random_params['iteration'] = random_results['iteration']\n",
    "random_params['score'] = 1- random_results['loss']\n",
    "random_params.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 贝叶斯优化\n",
    "bayes_params = pd.DataFrame(list(bayes_results['params']))\n",
    "bayes_params['loss'] = bayes_results['loss']\n",
    "bayes_params['iteration'] = bayes_results['iteration']\n",
    "bayes_params['score'] = 1- bayes_params['loss']\n",
    "bayes_params.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观察到两种搜索算法得出的\"num_leaves\"相去甚远, 下图展示出在搜索过程中, 随机搜索与原样本分布如其所愿基本保持一直, 而贝叶斯在代理模型TPE的引导下\"num_leaves\"分布变化巨大.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18, 6))\n",
    "# Plot the random search distribution and the bayes search distribution\n",
    "hyper='num_leaves'\n",
    "sns.kdeplot([sample(space[hyper]) for _ in range(1000)], label = 'Sampling Distribution')\n",
    "sns.kdeplot(random_params[hyper], label = 'Random Search')\n",
    "sns.kdeplot(bayes_params[hyper], label = 'Bayes Optimization')\n",
    "plt.legend(loc = 1)\n",
    "plt.title('{} Distribution'.format(hyper))\n",
    "plt.xlabel('{}'.format(hyper)); plt.ylabel('Density');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们发现两种搜索的提升算法也不一样. 与随机搜索的平等对待不同贝叶斯超过一半的时间在探索gbdt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig, axs = plt.subplots(1, 2, sharey = True, sharex = True)\n",
    "\n",
    "# Bar plots of boosting type\n",
    "random_params['boosting_type'].value_counts().plot.bar(ax = axs[0], figsize = (14, 6), color = 'orange', title = 'Random Search Boosting Type')\n",
    "bayes_params['boosting_type'].value_counts().plot.bar(ax = axs[1], figsize = (14, 6), color = 'green', title = 'Bayes Optimization Boosting Type');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "贝叶斯优化超参数演化过程，如下7幅图中, 展示出贝叶斯优化的过程中超参演化确实有一些趋势, 并非随机."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize = (24, 6))\n",
    "i = 0\n",
    "\n",
    "# Plot of four hyperparameters\n",
    "for i, hyper in enumerate(['colsample_bytree', 'learning_rate', 'min_child_samples', 'num_leaves']):\n",
    "    \n",
    "        # Scatterplot\n",
    "        sns.regplot('iteration', hyper, data = bayes_params, ax = axs[i])\n",
    "#         sns.lmplot('iteration', hyper, data = random_params)\n",
    "        axs[i].set(xlabel = 'Iteration', ylabel = '{}'.format(hyper), title = '{} over Search'.format(hyper));\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize = (18, 6))\n",
    "i = 0\n",
    "\n",
    "# Scatterplot of next three hyperparameters\n",
    "for i, hyper in enumerate(['reg_alpha', 'reg_lambda', 'subsample_for_bin']):\n",
    "        sns.regplot('iteration', hyper, data = bayes_params, ax = axs[i])\n",
    "        axs[i].set(xlabel = 'Iteration', ylabel = '{}'.format(hyper), title = '{} over Search'.format(hyper));\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果调参迭代次数足够过的话，可以测试是否会收敛"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC演化趋势"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备AUC表\n",
    "scores = pd.DataFrame({'ROC AUC': 1 - random_params['loss'], 'iteration': random_params['iteration'], 'search': 'random'})\n",
    "scores = scores.append(pd.DataFrame({'ROC AUC': 1 - bayes_params['loss'], 'iteration': bayes_params['iteration'], 'search': 'Bayes'}))\n",
    "\n",
    "scores['ROC AUC'] = scores['ROC AUC'].astype(np.float32)\n",
    "scores['iteration'] = scores['iteration'].astype(np.int32)\n",
    "\n",
    "sns.lmplot('iteration', 'ROC AUC', hue = 'search', data = scores, size = 8);\n",
    "plt.xlabel('Iteration'); plt.ylabel('ROC AUC'); plt.title(\"ROC AUC versus Iteration\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
